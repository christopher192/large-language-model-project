{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a6baad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import enum\n",
    "from google import genai\n",
    "from pprint import pprint\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from google.api_core import retry\n",
    "from IPython.display import HTML, Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1cfccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b4dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variables\n",
    "google_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "013ad8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have a really smart robot friend! That robot can do all sorts of things, like play games, tell you stories, and even draw pictures.\n",
      "\n",
      "That's because it has \"AI,\" which stands for \"Artificial Intelligence.\"\n",
      "\n",
      "Think of \"intelligence\" as being really good at learning and solving problems. You're intelligent because you can learn new things in school and figure out how to build a really cool LEGO tower!\n",
      "\n",
      "\"Artificial\" means it's not real, like a pretend playhouse.\n",
      "\n",
      "So, \"Artificial Intelligence\" is like giving a computer or robot a pretend brain that can learn and solve problems like you do!\n",
      "\n",
      "**Here's how it works in simple steps:**\n",
      "\n",
      "1.  **Show it lots of examples:** Imagine you want your robot to recognize cats. You'd show it thousands of pictures of cats, and tell it, \"This is a cat!\"\n",
      "\n",
      "2.  **It learns the patterns:** The robot's brain (its computer program) looks at all the pictures and learns what makes a cat a cat - things like pointy ears, whiskers, and a furry tail.\n",
      "\n",
      "3.  **Now it can guess!** When you show it a new picture, it can use what it learned to guess if it's a cat or not. It might say, \"I think this is a cat because it has pointy ears and whiskers!\"\n",
      "\n",
      "**AI is in lots of things you use every day!**\n",
      "\n",
      "*   **Siri and Alexa:** They understand what you say and answer your questions.\n",
      "*   **Video games:** They make the bad guys smart so they can try to beat you!\n",
      "*   **Netflix:** It uses AI to suggest movies and shows you might like.\n",
      "*   **Self-driving cars:** They use AI to see the road and drive safely.\n",
      "\n",
      "AI is still learning and getting smarter, just like you! It's a really cool and exciting field, and maybe one day you'll even build your own AI robot friend!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=google_api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain AI to me like I'm a kid.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e0920a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Imagine you have a really smart robot friend! That robot can do all sorts of things, like play games, tell you stories, and even draw pictures.\n",
       "\n",
       "That's because it has \"AI,\" which stands for \"Artificial Intelligence.\"\n",
       "\n",
       "Think of \"intelligence\" as being really good at learning and solving problems. You're intelligent because you can learn new things in school and figure out how to build a really cool LEGO tower!\n",
       "\n",
       "\"Artificial\" means it's not real, like a pretend playhouse.\n",
       "\n",
       "So, \"Artificial Intelligence\" is like giving a computer or robot a pretend brain that can learn and solve problems like you do!\n",
       "\n",
       "**Here's how it works in simple steps:**\n",
       "\n",
       "1.  **Show it lots of examples:** Imagine you want your robot to recognize cats. You'd show it thousands of pictures of cats, and tell it, \"This is a cat!\"\n",
       "\n",
       "2.  **It learns the patterns:** The robot's brain (its computer program) looks at all the pictures and learns what makes a cat a cat - things like pointy ears, whiskers, and a furry tail.\n",
       "\n",
       "3.  **Now it can guess!** When you show it a new picture, it can use what it learned to guess if it's a cat or not. It might say, \"I think this is a cat because it has pointy ears and whiskers!\"\n",
       "\n",
       "**AI is in lots of things you use every day!**\n",
       "\n",
       "*   **Siri and Alexa:** They understand what you say and answer your questions.\n",
       "*   **Video games:** They make the bad guys smart so they can try to beat you!\n",
       "*   **Netflix:** It uses AI to suggest movies and shows you might like.\n",
       "*   **Self-driving cars:** They use AI to see the road and drive safely.\n",
       "\n",
       "AI is still learning and getting smarter, just like you! It's a really cool and exciting field, and maybe one day you'll even build your own AI robot friend!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c76bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings, Zlork! It's nice to meet you. Is there anything I can help you with today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model='gemini-2.0-flash', history=[])\n",
    "response = chat.send_message('Hello! My name is Zlork.')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15073a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, Zlork, here's an interesting dinosaur fact for you:\n",
      "\n",
      "**Some dinosaurs may have had feathers, even if they weren't directly related to birds!**\n",
      "\n",
      "While we often picture dinosaurs as scaly reptiles, growing evidence shows that many dinosaurs, including some theropods (the group that includes T. Rex), had feathers. These feathers weren't necessarily for flight, though. They likely served other purposes like insulation, display, or even camouflage.\n",
      "\n",
      "For example, the *Yutyrannus huali*, a tyrannosauroid from China, is one of the largest known feathered dinosaurs. Its fossils showed evidence of downy, filament-like feathers covering much of its body. This suggests that even large predators in cooler climates might have benefited from having a feathery coat!\n",
      "\n",
      "So, the next time you think of dinosaurs, remember that many of them might have been a lot fluffier than you imagined!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Can you tell me something interesting about dinosaurs?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20ff78ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Zlork. I remember your name is Zlork.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Do you remember what my name is?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98fbef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "  print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2de353d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Gemini 2.0 Flash',\n",
      " 'display_name': 'Gemini 2.0 Flash',\n",
      " 'input_token_limit': 1048576,\n",
      " 'name': 'models/gemini-2.0-flash',\n",
      " 'output_token_limit': 8192,\n",
      " 'supported_actions': ['generateContent', 'countTokens'],\n",
      " 'tuned_model_info': {},\n",
      " 'version': '2.0'}\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "  if model.name == 'models/gemini-2.0-flash':\n",
    "    pprint(model.to_json_dict())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89e6184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## The Enduring Olive: A Keystone of Modern Society\n",
      "\n",
      "The olive, a humble drupe clinging to the branches of the _Olea europaea_, belies its profound importance in shaping modern society. More than just a flavorful addition to salads and tapenades, the olive and its derivatives have seeped into the very fabric of our culture, influencing cuisine, health, economics, agriculture, and even art and religion. Understanding the multifaceted impact of the olive reveals its enduring legacy and its critical role in the modern world.\n",
      "\n",
      "Perhaps the most readily apparent significance of the olive lies in its culinary applications. Olive oil, the liquid gold extracted from the fruit, has become a staple in kitchens worldwide. From the Mediterranean diet, renowned for its health benefits, to gourmet restaurants pushing culinary boundaries, olive oil serves as a fundamental ingredient. Its versatility is remarkable, used for sautéing, frying, grilling, baking, and even as a finishing drizzle. Its distinctive flavor profiles, ranging from delicate and fruity to\n"
     ]
    }
   ],
   "source": [
    "short_config = types.GenerateContentConfig(max_output_tokens=200)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=short_config,\n",
    "    contents='Write a 1000 word essay on the importance of olives in modern society.')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77f76c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From sun-kissed groves, a humble sphere,\n",
      "The olive reigns, dispelling fear.\n",
      "In salads bright, a savory grace,\n",
      "Or pressed to oil, a golden trace.\n",
      "\n",
      "On pizzas spread, a salty bite,\n",
      "In tapenade, a dark delight.\n",
      "A symbol old, of peace and health,\n",
      "The olive's worth, beyond all wealth.\n",
      "\n",
      "So raise a glass, to this small fruit,\n",
      "Whose flavor weaves, from branch to root,\n",
      "A tapestry of taste and time,\n",
      "The olive, truly, sublime.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=short_config,\n",
    "    contents='Write a short poem on the importance of olives in modern society.')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcc07b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purple\n",
      " -------------------------\n",
      "Mauve\n",
      " -------------------------\n",
      "Purple\n",
      " -------------------------\n",
      "Turquoise\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n"
     ]
    }
   ],
   "source": [
    "high_temp_config = types.GenerateContentConfig(temperature=2.0)\n",
    "\n",
    "for _ in range(5):\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=high_temp_config,\n",
    "      contents='Pick a random colour... (respond in a single word)')\n",
    "\n",
    "  if response.text:\n",
    "    print(response.text, '-' * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a515ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n"
     ]
    }
   ],
   "source": [
    "low_temp_config = types.GenerateContentConfig(temperature=0.0)\n",
    "\n",
    "for _ in range(5):\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=low_temp_config,\n",
    "      contents='Pick a random colour... (respond in a single word)')\n",
    "\n",
    "  if response.text:\n",
    "    print(response.text, '-' * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13d51e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jasper, a ginger tabby with a perpetually inquisitive twitch of his whiskers, was bored. Utterly, desperately bored. He had napped in sunbeams, batted at dust bunnies, and even begrudgingly accepted a cuddle from Mrs. Higgins, his human. The routine was stifling. He longed for something…more.\n",
      "\n",
      "One particularly dull afternoon, a gust of wind rattled the back door open a crack. Jasper, ever alert, pounced. He squeezed through the gap, the scent of damp earth and unfamiliar flowers filling his senses. This was it. Adventure.\n",
      "\n",
      "He stepped into a world he only glimpsed from the window – a sprawling garden teeming with life. Butterflies, like fluttering jewels, danced around vibrant rose bushes. Bees buzzed lazily, heavy with pollen. Jasper, mesmerized, stalked through the undergrowth, his senses on high alert.\n",
      "\n",
      "His first challenge came in the form of a fat bumblebee clinging precariously to a sunflower. Jasper, instincts blazing, crouched low, tail twitching. He sprang! The bee, startled, buzzed angrily and zoomed away, leaving Jasper tangled in the sunflower’s rough leaves. He emerged, covered in yellow dust, feeling foolish but undeterred.\n",
      "\n",
      "Next, he encountered a tiny, terrified mouse scurrying for cover. Normally, Jasper would have been all too eager to indulge in a chase, but today, something was different. He saw the fear in the mouse's eyes, the frantic scramble for survival. Instead of pouncing, he simply sat and watched, a strange empathy filling him. The mouse, sensing the lack of aggression, dared to peek out, then scurried safely into its burrow. Jasper felt a curious satisfaction, a feeling far more rewarding than a simple hunt.\n",
      "\n",
      "As dusk began to paint the sky in hues of orange and purple, Jasper found himself in a new, unfamiliar section of the garden. A towering oak tree stood sentinel, its branches draped with shimmering strands of spider silk. At the base of the tree, a small, dark hole beckoned. Curiosity, as always, got the better of him.\n",
      "\n",
      "He squeezed through the hole, finding himself in a cool, earthy tunnel. The air was damp and smelled of roots and secrets. He crept forward, his whiskers brushing against the cool dirt walls. Suddenly, he heard a soft chirping.\n",
      "\n",
      "He followed the sound until he reached a small, earthen chamber. There, nestled in a makeshift nest, were two tiny, helpless baby birds. Their mother was nowhere in sight. Jasper, his predatory instincts momentarily overridden, felt a pang of concern.\n",
      "\n",
      "He stayed with the chicks until the moon rose high in the sky, keeping them warm with his body. Finally, a frantic fluttering announced the mother bird's return. She landed in the chamber, chirping with relief, and began feeding her young.\n",
      "\n",
      "Jasper, his mission accomplished, felt a surge of contentment. He backed out of the tunnel, feeling oddly protective of the little family.\n",
      "\n",
      "As he emerged from the oak tree, he saw Mrs. Higgins frantically calling his name. Guilt pricked him. He trotted towards her, meowing apologetically.\n",
      "\n",
      "She scooped him up in a hug, relief washing over her face. \"Jasper! Where have you been? I was so worried!\"\n",
      "\n",
      "He purred into her shoulder, rubbing against her cheek. He couldn't tell her about his adventure, about the bee, the mouse, and the baby birds. But he knew, in his heart, that he had done something special.\n",
      "\n",
      "That night, curled up on his favorite cushion, Jasper wasn't bored. He was tired, yes, but more than that, he was fulfilled. He had discovered that adventure wasn't just about excitement and danger; it was about empathy, compassion, and the unexpected connections that could be found in the most ordinary of places. And he knew, with absolute certainty, that he would be back for more.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75f81aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=1,\n",
    "    max_output_tokens=5,\n",
    ")\n",
    "\n",
    "zero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\n",
    "Review: \"Her\" is a disturbing study revealing the direction\n",
    "humanity is headed if AI is allowed to keep evolving,\n",
    "unchecked. I wish there were more movies like this masterpiece.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723c3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "class Sentiment(enum.Enum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    NEGATIVE = \"negative\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"text/x.enum\",\n",
    "        response_schema=Sentiment\n",
    "    ),\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e09ba500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment.POSITIVE\n",
      "<enum 'Sentiment'>\n"
     ]
    }
   ],
   "source": [
    "enum_response = response.parsed\n",
    "print(enum_response)\n",
    "print(type(enum_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7539935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\"size\": \"large\",\n",
      "\"type\": \"normal\",\n",
      "\"ingredients\": [\"cheese\", \"pineapple\"]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n",
    "\n",
    "EXAMPLE:\n",
    "I want a small pizza with cheese, tomato sauce, and pepperoni.\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"small\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"cheese\", \"tomato sauce\", \"pepperoni\"]\n",
    "}\n",
    "```\n",
    "\n",
    "EXAMPLE:\n",
    "Can I get a large pizza with tomato sauce, basil and mozzarella\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"large\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n",
    "}\n",
    "```\n",
    "\n",
    "ORDER:\n",
    "\"\"\"\n",
    "\n",
    "customer_order = \"Give me a large with cheese & pineapple\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=1,\n",
    "        max_output_tokens=250,\n",
    "    ),\n",
    "    contents=[few_shot_prompt, customer_order])\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
