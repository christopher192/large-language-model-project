{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3\n",
      "\n",
      "ahaṃ bhavantaṃ gotamaṃ saraṇaṃ gacchāmi\n",
      "I go for refuge to the master Gotama\n",
      "\n",
      "\n",
      "DHP 130 sabbe tasanti daṇḍassa.\n",
      "All are fearful of a stick.\n",
      "\n",
      "MN 27 tathāgate saddhaṃ paṭilabhati\n"
     ]
    }
   ],
   "source": [
    "# Load vocab_class_3.csv and suttas.csv\n",
    "vocab_file = \"pali_class/vocab/vocab_class_3.csv\"\n",
    "sutta_file = \"pali_class/suttas.csv\"\n",
    "\n",
    "vocab_df = pd.read_csv(vocab_file)\n",
    "sutta_df = pd.read_csv(sutta_file, sep=\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "# Load exercises_class_3.txt\n",
    "exercises_file = \"pali_class/exercises/exercises_class_3.txt\"\n",
    "\n",
    "with open(exercises_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Display first few lines\n",
    "for line in lines[:10]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"attha 1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attho', 'atthaṃ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_word = vocab_df[vocab_df[\"pali\"] == user_input]\n",
    "search_result = {\n",
    "    'id': -1,\n",
    "    'pali': '',\n",
    "    'class_source': '',\n",
    "    'class_sutta': '',\n",
    "    'class_example': '', \n",
    "    'english_translation': ''\n",
    "}\n",
    "\n",
    "if len(match_word) > 0:\n",
    "    # Possible relavant declension and conjugation\n",
    "    prdc = []\n",
    "    search_result['id'] = match_word['id'].values[0]\n",
    "    search_result['pali'] = match_word['pali'].values[0]\n",
    "    \n",
    "    example_columns = [col for col in vocab_df.columns if \"example\" in col.lower()]\n",
    "\n",
    "    for col in example_columns:\n",
    "        sentence = match_word[col].values[0]\n",
    "\n",
    "        # Extract text inside <b>...</b>\n",
    "        match = re.findall(r\"<b>(.*?)</b>\", sentence)\n",
    "        \n",
    "        for m in match:\n",
    "            if m not in prdc:\n",
    "                prdc.append(m)\n",
    "else:\n",
    "    print(\"No match found\")\n",
    "\n",
    "prdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sutta_info(text):\n",
    "    \"\"\"Extract Sutta reference and (simpl) marker if present.\"\"\"\n",
    "    match = re.search(r'([A-Z]+ \\d+(?:\\.\\d+)?)\\s*(\\(simpl\\))?', text)\n",
    "\n",
    "    if match:\n",
    "        sutta_reference = match.group(1) # Extract Sutta reference\n",
    "        simpl_marker = match.group(2) if match.group(2) else \"\" # Extract (simpl) if found\n",
    "        return {\"sutta_reference\": sutta_reference, \"simpl_marker\": simpl_marker}\n",
    "\n",
    "    return None\n",
    "\n",
    "def clean_sentence(text, target_word):\n",
    "    \"\"\"Removes leading numbering and sutta reference from a sentence.\"\"\"\n",
    "    # Remove leading number + tab (e.g., \"4.\\t\")\n",
    "    text = re.sub(r'^\\d+\\.\\t', '', text)\n",
    "\n",
    "    # Remove sutta reference + (simpl) if present (e.g., \"AN 3.71 (simpl)\")\n",
    "    text = re.sub(r'([A-Z]+ \\d+(?:\\.\\d+)?)(?: \\(simpl\\))?$', '', text).strip()\n",
    "\n",
    "    # Highlight target word using <b></b>\n",
    "    if target_word:\n",
    "        text = re.sub(fr'\\b{re.escape(target_word)}\\b', fr'<b>{target_word}</b>', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'attho' found at line 64: 13.\tsādhu āyasmantaṃ sāriputtaṃ paṭibhātu etassa bhāsitassa attho SN 22.1 (simpl)\n",
      "Next sentence: It would be good if the meaning of this statement may become evident to Venerable Sāriputta. (so that he could explain it to us)\n"
     ]
    }
   ],
   "source": [
    "with open(exercises_file, encoding='utf-8') as f:\n",
    "    # content = f.read()\n",
    "    lines = f.readlines() # Read all lines into a list\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "            if prdc[0] in line: # If the word is found\n",
    "                print(f\"'{prdc[0]}' found at line {i+1}: {line.strip()}\")\n",
    "\n",
    "                # Get the next sentence (if available)\n",
    "                if i + 1 < len(lines):\n",
    "                    next_sentence = lines[i + 1].strip()\n",
    "                    print(f\"Next sentence: {next_sentence}\")\n",
    "\n",
    "                # Extract Sutta reference\n",
    "                sutta_info = extract_sutta_info(line.strip())\n",
    "\n",
    "                if sutta_info:\n",
    "                    if sutta_info['simpl_marker'] != '':     \n",
    "                        search_result['class_source'] = sutta_info['sutta_reference'] + \" \" + sutta_info['simpl_marker']\n",
    "                    else:\n",
    "                        search_result['class_source'] = sutta_info['sutta_reference']\n",
    "                \n",
    "                    # Get Sutta name\n",
    "                    # Remove spaces in `sutta_number` (e.g., \"AN 2.1\" → \"AN2.1\")\n",
    "                    sutta_number = sutta_info['sutta_reference'].replace(\" \", \"\")\n",
    "                    sutta_name = sutta_df[sutta_df[\"sutta_number\"] == sutta_number]\n",
    "\n",
    "                    search_result['class_sutta'] = sutta_name['sutta_name'].values[0]\n",
    "                \n",
    "                # Example Usage\n",
    "                sentence = line.strip()\n",
    "                cleaned_sentence = clean_sentence(sentence, prdc[0])\n",
    "\n",
    "                search_result['class_example'] = cleaned_sentence\n",
    "                search_result['english_translation'] = next_sentence\n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2597,\n",
       " 'pali': 'attha 1.1',\n",
       " 'class_source': 'SN 22.1 (simpl)',\n",
       " 'class_sutta': 'nakulapitusuttaṃ',\n",
       " 'class_example': 'sādhu āyasmantaṃ sāriputtaṃ paṭibhātu etassa bhāsitassa <b>attho</b>',\n",
       " 'english_translation': 'It would be good if the meaning of this statement may become evident to Venerable Sāriputta. (so that he could explain it to us)'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m sentence \u001b[38;5;241m=\u001b[39m match_word[col]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Extract text inside <b>...</b>\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<b>(.*?)</b>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m match:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m prdc:\n",
      "File \u001b[1;32mc:\\Users\\tellw\\anaconda3\\envs\\llm\\Lib\\re\\__init__.py:217\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m \n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 'float'"
     ]
    }
   ],
   "source": [
    "batch_process = vocab_df[\"pali\"].tolist()\n",
    "\n",
    "for b in batch_process:\n",
    "    match_word = vocab_df[vocab_df[\"pali\"] == b]\n",
    "    search_result = {\n",
    "        'id': -1,\n",
    "        'pali': '',\n",
    "        'class_source': '',\n",
    "        'class_sutta': '',\n",
    "        'class_example': '', \n",
    "        'english_translation': ''\n",
    "    }\n",
    "\n",
    "    # Possible relavant declension and conjugation\n",
    "    prdc = []\n",
    "    search_result['id'] = match_word['id'].values[0]\n",
    "    search_result['pali'] = match_word['pali'].values[0]\n",
    "    \n",
    "    example_columns = [col for col in vocab_df.columns if \"example\" in col.lower()]\n",
    "    \n",
    "    for col in example_columns:\n",
    "        sentence = match_word[col].values[0]\n",
    "\n",
    "        # Extract text inside <b>...</b>\n",
    "        match = re.findall(r\"<b>(.*?)</b>\", sentence)\n",
    "        \n",
    "        for m in match:\n",
    "            if m not in prdc:\n",
    "                prdc.append(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
